\section{Rate distortion}
















If the input is not in the domain of definition, the approximate map outputs a random sequence of $d$ bits.
If proportion $f$ of the bit patterns are \emph{undefined}, then the probability that an element not in the domain of definition correctly maps to undefined is $f$ and the probability that it incorrectly maps to some valid value is $1-f$.



\emph{Rate-distortion} is given by the following definition.

Each element $y$ in the range of $\Fun{f}$ has a \emph{prefix-free} code denoted by $E(y)$ consisting of $\BL(y)$ bits.
We provide an average of $r$ bits per element in the domain of definition for representing the mapping $\Fun{f}$, denoted the \emph{rate}.
Given a rate $r$ and a false positive rate $\fprate$ (where the element randomly maps to some representation in the codomain), the space required for $\APFun{f}[\fprate][r]$ is $r + \log_2 \frac{1}{\fprate}$ bits per element in the domain of definition.

Distortion is a measure of the error between $y' = \APFun{f}(x)$ and $y = \Fun{f}(x)$, denoted by $\Fun{d}(y',y)$ where $\Fun{d}(y,y) = 0$.
The \emph{rate distortion} is the \emph{expected} distortion over the domain of definition,
\begin{equation}
\gamma = \sum_{x \in \Dod(\Fun{f})} \Fun{p}(x) \Fun{d}(\APFun{f}(x),\Fun{f}(x))\,,
\end{equation}
where we typically assume a uniform distribution over the domain of definition, i.e., $\Fun{p}(x) = \frac{1}{\Card{\Dod(\Fun{f})}}$.
Naturally, the rate distortion is a function of the rate and the \emph{entropy}.

The usual model is that bits in the representation of are randomly flipped, resulting in distortion.
Thus, we want to minimize the bit length of more likely inputs to minimize the rate distortion.
If the rate is greater than the entropy, it is possible to provide an error-free representation over the domain of definition with a minimum expected bit length of $\Entropy{X} + \log_2 \frac{1}{\fprate}$.
If the input is uniformly distributed, this simplifies to $\log_2 \frac{m}{\fprate}$ where $m = \Card{\Dod(\Fun{f})}$.

If we have fewer than $\Entropy{X} + \log_2 \frac{1}{\fprate}$ bits, then we have a \emph{rate distortion} $\gamma$.

Typically, to minimize the rate distortion given a rate $r$, we make as many of the most likely inputs have zero distortion and we make less likely inputs have as little distortion as we can manage.

we assign the shortest prefix-free codes to the most likely inputs.


A general measure $\Fun{d}$ is the \emph{hamming distance}, where similar elements may be mapped to values with a small hamming distance.




Consider the following way we can arrive at a random approximate map as previously defined, with false positive and false negatives.
Suppose we have a domain of definition of size $m$, a rate $r$, and a false positive rate $\fprate$.
To have a rate distortion of zero over the domain of definition, we need $m \left( \Entropy{X} + \log_2 \frac{1}{\fprate}\right)$ bits as an expected lower-bound.

Suppose we only have $k$ bits, however, and we wish to fix the false positive rate at $\fprate$.
Then, we can decrease $m$ to $t$, $t < m$.
Ideally, we remove any $m-t$ elements in the domain of definition with the greatest entropy.

First, suppose they are uniformly distributed.
Then, we can remove any $m-t$ elements, resulting in
\begin{equation}
k = t \left( \Entropy{X} + \log_2 \frac{1}{\fprate}\right)\,,
\end{equation}
solving for $t$ yields
\begin{equation}
t = \frac{k}{\Entropy{X} + \log_2 \frac{1}{\fprate}}
\end{equation}
which results in a true positive rate $\tprate = \frac{t}{m} = \frac{k}{S}$ bits, where $S$ is the space lower-bound for a true positive rate of $1$.
